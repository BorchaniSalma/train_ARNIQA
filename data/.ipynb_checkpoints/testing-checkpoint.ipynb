{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac43df64-ed19-4a93-9482-475615bb2e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import Union, Tuple\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import scipy\n",
    "\n",
    "\n",
    "def sign(x: float) -> int:\n",
    "    return 1 if x >= 0 else -1\n",
    "\n",
    "\n",
    "def mapmm(x: torch.Tensor) -> torch.Tensor:\n",
    "    minx = torch.min(x)\n",
    "    maxx = torch.max(x)\n",
    "    if minx < maxx:\n",
    "        x = (x - minx) / (maxx - minx)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fspecial(filter_type: str, p2: Union[int, Tuple[int, int]], p3: Union[int, float] = None) -> np.ndarray:\n",
    "    if filter_type == 'gaussian':\n",
    "        m, n = [(ss - 1.) / 2. for ss in p2]\n",
    "        y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "        h = np.exp(-(x * x + y * y) / (2. * p3 * p3))\n",
    "        h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "        sumh = h.sum()\n",
    "        if sumh != 0:\n",
    "            h /= sumh\n",
    "\n",
    "        return h\n",
    "\n",
    "    elif filter_type == 'disk':\n",
    "        rad = p2\n",
    "        crad = math.ceil(rad - 0.5)\n",
    "\n",
    "        x, y = np.ogrid[-rad: rad + 1, -rad: rad + 1]\n",
    "        y = np.tile(y.transpose(), y.shape[1])\n",
    "        x = np.tile(x, x.shape[0]).transpose()\n",
    "\n",
    "        y = np.abs(y)\n",
    "        x = np.abs(x)\n",
    "\n",
    "        maxxy = np.maximum(x, y)\n",
    "        minxy = np.minimum(x, y)\n",
    "\n",
    "        r1 = (rad ** 2 - (maxxy + 0.5) ** 2)\n",
    "        r2 = (rad ** 2 - (minxy - 0.5) ** 2)\n",
    "\n",
    "        if (r1 > 0).all():\n",
    "            warn_m1 = r1 ** 0.5\n",
    "        else:\n",
    "            warn_m1 = 0\n",
    "        if (r2 > 0).all():\n",
    "            warn_m2 = r2 ** 0.5\n",
    "        else:\n",
    "            warn_m2 = 0\n",
    "\n",
    "        m1 = (rad ** 2 < (maxxy + 0.5) ** 2 + (minxy - 0.5) ** 2) * (minxy - 0.5) + (\n",
    "                rad ** 2 >= (maxxy + 0.5) ** 2 + (minxy - 0.5) ** 2) * warn_m1\n",
    "        m2 = (rad ** 2 > (maxxy - 0.5) ** 2 + (minxy + 0.5) ** 2) * (minxy + 0.5) + (\n",
    "                rad ** 2 <= (maxxy - 0.5) ** 2 + (minxy + 0.5) ** 2) * warn_m2\n",
    "\n",
    "        sgrid = (rad ** 2 * (0.5 * (np.arcsin(m2 / rad) - np.arcsin(m1 / rad)) +\n",
    "                             0.25 * (np.sin(2 * np.arcsin(m2 / rad)) - np.sin(2 * np.arcsin(m1 / rad)))) - (\n",
    "                         maxxy - 0.5) * (m2 - m1) + (m1 - minxy + 0.5)) * np.logical_or(\n",
    "            np.logical_and((rad ** 2 < (maxxy + 0.5) ** 2 + (minxy + 0.5) ** 2),\n",
    "                           (rad ** 2 > (maxxy - 0.5) ** 2 + (minxy - 0.5) ** 2)),\n",
    "            np.logical_and(np.logical_and(minxy == 0, maxxy - 0.5 < rad), maxxy + 0.5 >= rad))\n",
    "\n",
    "        sgrid = sgrid + ((maxxy + 0.5) ** 2 + (minxy + 0.5) ** 2 < rad ** 2)\n",
    "        sgrid[crad, crad] = np.minimum(math.pi * rad ** 2, math.pi / 2)\n",
    "        if (crad > 0) and (rad > crad - 0.5) and (rad ** 2 < (crad - 0.5) ** 2 + 0.25):\n",
    "            m1 = np.sqrt(rad ** 2 - (crad - 0.5) ** 2)\n",
    "            m1n = m1 / rad\n",
    "            sg0 = 2 * (rad ** 2 * (0.5 * np.arcsin(m1n) + 0.25 * np.sin(2 * np.arcsin(m1n))) - m1 * (crad - 0.5))\n",
    "            sgrid[2 * crad, crad] = sg0\n",
    "            sgrid[crad, 2 * crad] = sg0\n",
    "            sgrid[crad, 0] = sg0\n",
    "            sgrid[0, crad] = sg0\n",
    "            sgrid[2 * crad, crad] = sgrid[2 * crad, crad] - sg0\n",
    "            sgrid[crad, 2 * crad] = sgrid[crad, 2 * crad] - sg0\n",
    "            sgrid[crad, 2] = sgrid[crad, 2] - sg0\n",
    "            sgrid[2, crad] = sgrid[2, crad + 1] - sg0\n",
    "\n",
    "        sgrid[crad, crad] = np.minimum(sgrid[crad, crad], 1)\n",
    "        h = sgrid / np.sum(sgrid)\n",
    "        return h\n",
    "    elif filter_type == 'motion':\n",
    "\n",
    "        eps = 2.2204e-16\n",
    "        length = max(1, p2)\n",
    "        half_len = (length - 1) / 2.\n",
    "        phi = (p3 % 180) / 180 * math.pi\n",
    "\n",
    "        cosphi = math.cos(phi)\n",
    "        sinphi = math.sin(phi)\n",
    "        xsign = sign(cosphi)\n",
    "        linewdt = 1\n",
    "\n",
    "        sx = int(half_len * cosphi + linewdt * xsign - length * eps)\n",
    "        sy = int(half_len * sinphi + linewdt - length * eps)\n",
    "        x, y = np.mgrid[0:sx + (1 * xsign):xsign, 0:sy + 1]\n",
    "        x = x.transpose()\n",
    "        y = y.transpose()\n",
    "\n",
    "        dist2line = (y * cosphi - x * sinphi)\n",
    "        rad = (x ** 2 + y ** 2) ** 0.5\n",
    "\n",
    "        lastpix = np.where(np.logical_and((rad >= half_len), (abs(dist2line) <= linewdt)))\n",
    "        x2lastpix = half_len - np.abs((x[lastpix] + dist2line[lastpix] * sinphi) / cosphi);\n",
    "\n",
    "        dist2line[lastpix] = np.sqrt(dist2line[lastpix] ** 2 + x2lastpix ** 2)\n",
    "        dist2line = linewdt + eps - np.abs(dist2line)\n",
    "        dist2line[dist2line < 0] = 0\n",
    "\n",
    "        h = np.rot90(dist2line, 2)\n",
    "        tmp_h = np.zeros((h.shape[0] * 2 - 1, h.shape[1] * 2 - 1))\n",
    "        tmp_h[0:h.shape[0], 0:h.shape[1]] = h\n",
    "        tmp_h[(h.shape[0]) - 1:, h.shape[1] - 1:] = dist2line\n",
    "        h = tmp_h\n",
    "\n",
    "        h /= np.sum(h) + eps * length * length\n",
    "\n",
    "        if cosphi > 0:\n",
    "            h = np.flipud(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Filter type {filter_type} not implemented\")\n",
    "\n",
    "\n",
    "def filter2D(img: torch.Tensor, kernel: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"PyTorch version of cv2.filter2D\n",
    "    Args:\n",
    "        img (Tensor): (b, c, h, w)\n",
    "        kernel (Tensor): (b, k, k)\n",
    "    \"\"\"\n",
    "    img = img.float()\n",
    "    k1 = kernel.size(-2)\n",
    "    k2 = kernel.size(-1)\n",
    "\n",
    "    b, c, h, w = img.size()\n",
    "    if k1 % 2 == 1 or k2 % 2 == 1:\n",
    "        img = F.pad(img, (k2 // 2, k2 // 2, k1 // 2, k1 // 2), mode='replicate')\n",
    "    else:\n",
    "        raise ValueError('Wrong kernel size')\n",
    "\n",
    "    ph, pw = img.size()[-2:]\n",
    "\n",
    "    if kernel.size(0) == 1:\n",
    "        # apply the same kernel to all batch images\n",
    "        img = img.view(b * c, 1, ph, pw)\n",
    "        kernel = kernel.view(1, 1, k1, k2)\n",
    "        return F.conv2d(img, kernel, padding=0).view(b, c, h, w)\n",
    "    else:\n",
    "        img = img.view(1, b * c, ph, pw)\n",
    "        kernel = kernel.view(b, 1, k1, k2).repeat(1, c, 1, 1).view(b * c, 1, k1, k2)\n",
    "        return F.conv2d(img, kernel, groups=b * c).view(b, c, h, w)\n",
    "\n",
    "\n",
    "def curves(xx: torch.Tensor, coef: float) -> torch.Tensor:\n",
    "    if type(coef) == list:\n",
    "        coef = [[0.3, 0.5, 0.7],\n",
    "                [coef[0], 0.5, coef[1]]]\n",
    "    else:\n",
    "        coef = [[0.5], [coef]]\n",
    "\n",
    "    x = np.array([0] + [p for p in coef[0]] + [1])\n",
    "    y = np.array([0] + [p for p in coef[1]] + [1])\n",
    "\n",
    "    cs = spline(x, y)\n",
    "\n",
    "    yy = ppval(cs, xx)\n",
    "\n",
    "    yy = torch.clamp(yy, 0, 1)\n",
    "\n",
    "    return yy\n",
    "\n",
    "\n",
    "def spline(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    n = x.shape[0]\n",
    "    dd = 1\n",
    "    dx = np.diff(x)\n",
    "    divdif = np.diff(y) / dx\n",
    "\n",
    "    if n == 3:\n",
    "        y[1:3] = divdif\n",
    "        y[2] = np.diff(divdif.T).T / (x[2] - x[0])\n",
    "        y[1] -= y[2] * dx[0]\n",
    "        dlk = y[[2, 1, 0]].shape[0]\n",
    "        l = x[[0, 2]].shape[0] - 1\n",
    "        dl = np.prod(dd) * l\n",
    "        k = np.fix(dlk / dl + 100 * 2.2204e-16)\n",
    "\n",
    "        pp = (x[[0, 2]], y[[2, 1, 0]], l, int(k), dd)\n",
    "\n",
    "    elif n > 3:\n",
    "        b = np.zeros(n)\n",
    "        b[1:n - 1] = 3 * (dx[1:n] * divdif[0:n - 2] + dx[0:n - 2] * divdif[1:n])\n",
    "\n",
    "        x31 = x[2] - x[0]\n",
    "        xn = x[n - 1] - x[n - 3]\n",
    "\n",
    "        b[0] = ((dx[0] + 2 * x31) * dx[1] * divdif[0] + dx[0] ** 2 * divdif[1]) / x31\n",
    "        b[n - 1] = (dx[n - 2] ** 2 * divdif[n - 3] + (2 * xn + dx[n - 2]) * dx[n - 3] * divdif[n - 2]) / xn;\n",
    "\n",
    "        dxt = dx.T\n",
    "        c = np.zeros((3, 5))\n",
    "        c[0, :] = [x31] + list(dxt[0:n - 2]) + [0]\n",
    "        c[1, :] = [dxt[1]] + list(2 * (dxt[1:n - 1] + dxt[0:n - 2])) + [dxt[n - 3]]\n",
    "        c[2, :] = [0] + list(dxt[1:n - 1]) + [xn]\n",
    "\n",
    "        c = scipy.sparse.dia_matrix((c, [-1, 0, 1]), shape=(5, 5))\n",
    "        c = scipy.sparse.csc_matrix(c)\n",
    "        ic = scipy.sparse.linalg.inv(c)\n",
    "        s = b * ic\n",
    "\n",
    "        n = x.shape[0]\n",
    "        d = 1\n",
    "        dxd = dx\n",
    "\n",
    "        dzzdx = (divdif - s[0:n - 1]) / dxd\n",
    "        dzdxdx = (s[1:n] - divdif) / dxd\n",
    "\n",
    "        coefs = np.vstack(((dzdxdx - dzzdx) / dxd, 2 * dzzdx - dzdxdx, s[0:n - 1], y[0:n - 1])).T\n",
    "\n",
    "        pp = (x, coefs, x.shape[0], x.shape[0], d)\n",
    "    else:\n",
    "        raise ValueError('x.shape[0] must be >= 3')\n",
    "\n",
    "    return pp\n",
    "\n",
    "\n",
    "def ppval(pp: np.ndarray, xx: torch.Tensor) -> torch.Tensor:\n",
    "    lx = torch.numel(xx)\n",
    "    xs = xx.reshape(1, lx)\n",
    "    b, c, l, k, dd = pp\n",
    "    b = torch.as_tensor(b, device=xx.device)\n",
    "    ranges = b.clone()\n",
    "    ranges[0] = -torch.inf\n",
    "    ranges[-1] = torch.inf\n",
    "    index = histc(xs, ranges)\n",
    "\n",
    "    xs = xs - b[index]\n",
    "\n",
    "    c = torch.as_tensor(c, device=xx.device)\n",
    "\n",
    "    if len(c.shape) == 1:\n",
    "        v = c[0]\n",
    "        for i in range(1, k):\n",
    "            v = xs * v + c[i]\n",
    "    else:\n",
    "        v = c[index, 0]\n",
    "\n",
    "        for i in range(1, k - 1):\n",
    "            v = xs * v + c[index, i]\n",
    "    v = v.view(xx.shape)\n",
    "    return v\n",
    "\n",
    "\n",
    "def histc(x: torch.Tensor, binranges: torch.Tensor) -> torch.Tensor:\n",
    "    indices = torch.bucketize(x, binranges)\n",
    "    return torch.remainder(indices, len(binranges)) - 1\n",
    "\n",
    "\n",
    "def imscatter(x: torch.Tensor, amount: float, iterations=1) -> torch.Tensor:\n",
    "    y = x\n",
    "    for i in range(iterations):\n",
    "        shiftmap = torch.randn((2, x.shape[1], x.shape[2]), device=x.device) * amount\n",
    "\n",
    "        sy = shiftmap[0, :, :]\n",
    "        sx = shiftmap[1, :, :]\n",
    "\n",
    "        m_sx = torch.ceil(torch.abs(torch.max(sx))).to(torch.int32)\n",
    "        m_sy = torch.ceil(torch.abs(torch.max(sy))).to(torch.int32)\n",
    "\n",
    "        y = F.pad(y, (m_sy, m_sy), mode='replicate')\n",
    "        y = F.pad(y.transpose(2, 1), (m_sx, m_sx), mode='replicate').transpose(2, 1)\n",
    "\n",
    "        sy = F.pad(sy, (m_sy, m_sy), mode='replicate')\n",
    "        sy = F.pad(sy.transpose(1, 0), (m_sx, m_sx), mode='replicate').transpose(1, 0)\n",
    "        sx = F.pad(sx, (m_sy, m_sy), mode='replicate')\n",
    "        sx = F.pad(sx.transpose(1, 0), (m_sx, m_sx), mode='replicate').transpose(1, 0)\n",
    "\n",
    "        xx, yy = torch.as_tensor(np.mgrid[0:y.shape[1], 0:y.shape[2]], device=x.device)\n",
    "\n",
    "        z = torch.zeros_like(y)\n",
    "        bx = (xx - sx)\n",
    "        by = (yy - sy)\n",
    "        for i in range(3):\n",
    "            j = bilinear_interpolate_torch(y[i, ...], by, bx)\n",
    "            z[i, :, :] = j\n",
    "\n",
    "        y = z[:, m_sy:m_sy + x.shape[1], m_sx:m_sx + x.shape[2]]\n",
    "    return y\n",
    "\n",
    "\n",
    "def bilinear_interpolate_torch(im: torch.Tensor, x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    dtype_long = torch.LongTensor\n",
    "\n",
    "    x0 = torch.floor(x).type(dtype_long).to(im.device)\n",
    "    x1 = x0 + 1\n",
    "\n",
    "    y0 = torch.floor(y).type(dtype_long).to(im.device)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1] - 1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1] - 1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0] - 1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0] - 1)\n",
    "\n",
    "    Ia = im[y0, x0]\n",
    "    Ib = im[y1, x0]\n",
    "    Ic = im[y0, x1]\n",
    "    Id = im[y1, x1]\n",
    "\n",
    "    R1 = Ia * (x1 - x) / (x1 - x0 + eps) + Ic * (x - x0) / (x1 - x0 + eps)\n",
    "    R2 = Ib * (x1 - x) / (x1 - x0 + eps) + Id * (x - x0) / (x1 - x0 + eps)\n",
    "    P = R1 * (y1 - y) / (y1 - y0 + eps) + R2 * (y - y0) / (y1 - y0 + eps)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d43eb540-5307-4259-ba25-2f10bc510cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io.image import decode_jpeg, encode_jpeg\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "import io\n",
    "from PIL import Image\n",
    "import ctypes\n",
    "import kornia\n",
    "def gaussian_blur(x: torch.Tensor, blur_sigma: int = 0.1) -> torch.Tensor:\n",
    "    fs = 2 * math.ceil(2 * blur_sigma) + 1\n",
    "    h = fspecial('gaussian', (fs, fs), blur_sigma)\n",
    "    h = torch.from_numpy(h).float()\n",
    "\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "    y = filter2D(x, h.unsqueeze(0)).squeeze(0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def lens_blur(x: torch.Tensor, radius: int) -> torch.Tensor:\n",
    "    h = fspecial('disk', radius)\n",
    "    h = torch.from_numpy(h).float()\n",
    "\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "    y = filter2D(x, h.unsqueeze(0)).squeeze(0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def motion_blur(x: torch.Tensor, radius: int, angle: bool = None) -> torch.Tensor:\n",
    "    if angle is None:\n",
    "        angle = random.randint(0, 180)\n",
    "    h = fspecial('motion', radius, angle)\n",
    "    h = torch.from_numpy(h.copy()).float()\n",
    "\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "    y = filter2D(x, h.unsqueeze(0)).squeeze(0)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def white_noise(x: torch.Tensor, var: float, clip: bool = True, rounds: bool = False) -> torch.Tensor:\n",
    "    noise = torch.randn(*x.size(), dtype=x.dtype) * math.sqrt(var)\n",
    "\n",
    "    y = x + noise\n",
    "\n",
    "    if clip and rounds:\n",
    "        y = torch.clip((y * 255.0).round(), 0, 255) / 255.\n",
    "    elif clip:\n",
    "        y = torch.clip(y, 0, 1)\n",
    "    elif rounds:\n",
    "        y = (y * 255.0).round() / 255.\n",
    "    return y\n",
    "\n",
    "\n",
    "def non_eccentricity_patch(x: torch.Tensor, pnum: int) -> torch.Tensor:\n",
    "    y = x\n",
    "    patch_size = [16, 16]\n",
    "    radius = 16\n",
    "    h_min = radius\n",
    "    w_min = radius\n",
    "    c, h, w = x.shape\n",
    "\n",
    "    h_max = h - patch_size[0] - radius\n",
    "    w_max = w - patch_size[1] - radius\n",
    "\n",
    "    for i in range(pnum):\n",
    "        w_start = round(random.random() * (w_max - w_min)) + w_min\n",
    "        h_start = round(random.random() * (h_max - h_min)) + h_min\n",
    "        patch = y[:, h_start:h_start + patch_size[0], w_start:w_start + patch_size[0]]\n",
    "\n",
    "        rand_w_start = round((random.random() - 0.5) * radius + w_start)\n",
    "        rand_h_start = round((random.random() - 0.5) * radius + h_start)\n",
    "        y[:, rand_h_start:rand_h_start + patch_size[0], rand_w_start:rand_w_start + patch_size[0]] = patch\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def pixelate(x: torch.Tensor, strength: float) -> torch.Tensor:\n",
    "    z = 0.95 - strength ** 0.6\n",
    "    c, h, w = x.shape\n",
    "\n",
    "    ylo = kornia.geometry.transform.resize(x, (int(h * z), int(w * z)), 'nearest')\n",
    "    y = kornia.geometry.transform.resize(ylo, (h, w), 'nearest')\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd612ca-1370-4c95-b591-cdb976c99072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define distortion functions\n",
    "li_distort = [\n",
    "    lambda x, value: white_noise(x, value, False, False),\n",
    "    lambda x, value: gaussian_blur(x, value),\n",
    "    lambda x, value: lens_blur(x, value),\n",
    "    lambda x, value: motion_blur(x, value*5, np.random.rand(1)*360),\n",
    "    lambda x, value: pixelate(x, value*0.5),\n",
    "    lambda x, value: non_eccentricity_patch(x, int(value))\n",
    "]\n",
    "\n",
    "\n",
    "def get_distortions_composition(max_distortions, num_levels):\n",
    "    # Randomly select distortions\n",
    "    selected_distortions = np.random.choice(li_distort, max_distortions, replace=False).tolist()\n",
    "\n",
    "    # Randomly choose values for the selected distortions\n",
    "    selected_values = [np.random.rand() for _ in range(max_distortions)]\n",
    "\n",
    "    return selected_distortions, selected_values\n",
    "\n",
    "def distort_decam_images(image: torch.Tensor, distort_functions: list = None, distort_values: list = None,\n",
    "                   max_distortions: int = 4, num_levels: int = 5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Distorts an image using the distortion composition obtained with the image degradation model.\n",
    "\n",
    "    Args:\n",
    "        image (Tensor): image to distort\n",
    "        distort_functions (list): list of the distortion functions to apply to the image. If None, the functions are randomly chosen.\n",
    "        distort_values (list): list of the values of the distortion functions to apply to the image. If None, the values are randomly chosen.\n",
    "        max_distortions (int): maximum number of distortions to apply to the image\n",
    "        num_levels (int): number of levels of distortion that can be applied to the image\n",
    "\n",
    "    Returns:\n",
    "        image (Tensor): distorted image\n",
    "        distort_functions (list): list of the distortion functions applied to the image\n",
    "        distort_values (list): list of the values of the distortion functions applied to the image\n",
    "    \"\"\"\n",
    "    if distort_functions is None or distort_values is None:\n",
    "        distort_functions, distort_values = get_distortions_composition(max_distortions, num_levels)\n",
    "\n",
    "    for distortion, value in zip(distort_functions, distort_values):\n",
    "        image = distortion(image, value)\n",
    "        image = image.to(torch.float32)\n",
    "        image = torch.clip(image, 0, 1)\n",
    "\n",
    "\n",
    "    return image, distort_functions, distort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e707302-3376-4beb-b640-1f0808054f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_image(image: torch.Tensor, title: str = \"Distorted Image\"):\n",
    "    \"\"\"\n",
    "    Plot the given image.\n",
    "\n",
    "    Args:\n",
    "        image (Tensor): image to plot\n",
    "        title (str): title of the plot\n",
    "    \"\"\"\n",
    "    plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "775928a9-b089-4d07-a2dc-2efd8cc73fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import os\n",
    "\n",
    "class DECAMDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DECAM dataset class used for pre-training the encoders for IQA.\n",
    "\n",
    "    Args:\n",
    "        root (string): root directory of the dataset\n",
    "        patch_size (int): size of the patches to extract from the images\n",
    "        max_distortions (int): maximum number of distortions to apply to the images\n",
    "        num_levels (int): number of levels of distortion to apply to the images\n",
    "        pristine_prob (float): probability of not distorting the images\n",
    "\n",
    "    Returns:\n",
    "        dictionary with keys:\n",
    "            img_A_orig (Tensor): first view of the image pair\n",
    "            img_B_orig (Tensor): second view of the image pair\n",
    "            img_A_name (string): name of the image of the first view of the image pair\n",
    "            img_B_name (string): name of the image of the second view of the image pair\n",
    "            distortion_functions (list): list of the names of the distortion functions applied to the images\n",
    "            distortion_values (list): list of the values of the distortion functions applied to the images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 patch_size: int = 224,\n",
    "                 max_distortions: int = 4,\n",
    "                 num_levels: int = 5,\n",
    "                 pristine_prob: float = 0.05):\n",
    "\n",
    "        root = Path(root)\n",
    "\n",
    "        \n",
    "        filenames_csv_path = \"../data/decam_dr10_good_exp.csv\"\n",
    "        exp_df = pd.read_csv(filenames_csv_path, header=None, names=[\"expnum\"])\n",
    "\n",
    "        # Path to FITS file containing image data\n",
    "        file_path = \"/global/cfs/cdirs/cosmo/work/legacysurvey/dr10/survey-ccds-decam-dr10.fits.gz\"\n",
    "        image_table = Table.read(file_path)\n",
    "\n",
    "        # List to store paths of selected images\n",
    "        self.ref_images = []\n",
    "        self.hdu_numbers = []\n",
    "\n",
    "        test = image_table[:400]\n",
    "        idx = np.isin(test[\"expnum\"], exp_df[\"expnum\"])\n",
    "        matched_exp = test[idx]\n",
    "        self.ref_images =  matched_exp[\"image_filename\"]\n",
    "        self.hdu_numbers = matched_exp['image_hdu']\n",
    "\n",
    "\n",
    "        # Convert paths to Path objects\n",
    "        self.ref_images = [Path(root,path) for path in self.ref_images]\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.max_distortions = max_distortions\n",
    "        self.num_levels = num_levels\n",
    "        self.pristine_prob = pristine_prob\n",
    "\n",
    "        assert 0 <= self.max_distortions <= 7, \"The parameter max_distortions must be in the range [0, 7]\"\n",
    "        assert 1 <= self.num_levels <= 5, \"The parameter num_levels must be in the range [1, 5]\"\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        img_A_path = self.ref_images[index]\n",
    "        hdu_number = self.hdu_numbers[index]\n",
    "        hdul_A = fits.open(img_A_path)\n",
    "        img_A = hdul_A[hdu_number].data\n",
    "\n",
    "        # Select another exposure randomly\n",
    "        other_exp_index = np.random.choice(np.setdiff1d(range(len(self.ref_images)), [index]))\n",
    "        img_B_path = self.ref_images[other_exp_index]\n",
    "        hdul_B = fits.open(img_B_path)\n",
    "        img_B = hdul_B[hdu_number].data\n",
    "        \n",
    "        # Resize and crop\n",
    "        img_A_orig = torch.tensor(img_A[512:1024, 512:1024]).unsqueeze(0)\n",
    "        img_B_orig = torch.tensor(img_B[512:1024, 512:1024]).unsqueeze(0)\n",
    "\n",
    "\n",
    "        distort_functions_A = []\n",
    "        distort_values_A = []\n",
    "        distort_functions_B = []\n",
    "        distort_values_B = []\n",
    "\n",
    "        # Distort images with (1 - self.pristine_prob) probability for image A\n",
    "        if random.random() > self.pristine_prob and self.max_distortions > 0:\n",
    "            img_A_orig, distort_functions_A, distort_values_A = distort_decam_images(img_A_orig,\n",
    "                                                                                 max_distortions=self.max_distortions,\n",
    "                                                                                 num_levels=self.num_levels)\n",
    "\n",
    "        # Distort images with (1 - self.pristine_prob) probability for image B\n",
    "        if random.random() > self.pristine_prob and self.max_distortions > 0:\n",
    "            img_B_orig, distort_functions_B, distort_values_B = distort_decam_images(img_B_orig,\n",
    "                                                                                 max_distortions=self.max_distortions,\n",
    "                                                                                 num_levels=self.num_levels)\n",
    "\n",
    "\n",
    "        # Pad to make the length of distort_functions and distort_values equal for all samples\n",
    "        distort_functions_A = [f.__name__ for f in distort_functions_A]\n",
    "        distort_functions_A += [\"\"] * (self.max_distortions - len(distort_functions_A))\n",
    "        distort_values_A += [torch.inf] * (self.max_distortions - len(distort_values_A))\n",
    "\n",
    "        distort_functions_B = [f.__name__ for f in distort_functions_B]\n",
    "        distort_functions_B += [\"\"] * (self.max_distortions - len(distort_functions_B))\n",
    "        distort_values_B += [torch.inf] * (self.max_distortions - len(distort_values_B))\n",
    "        \n",
    "        plot_image(img_A_orig, title=\"Image A\")\n",
    "        plot_image(img_B_orig, title=\"Image B\")\n",
    "\n",
    "        return {\n",
    "            \"img_A_orig\": img_A_orig,\"img_B_orig\": img_B_orig,\n",
    "            \"distortion_functions_A\": distort_functions_A, \"distortion_values_A\": distort_values_A,\n",
    "            \"distortion_functions_B\": distort_functions_B, \"distortion_values_B\": distort_values_B\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ref_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d761b8da-e680-4497-990b-773395958749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the training dataset and dataloader\n",
    "train_dataset = DECAMDataset(root=\"/global/cfs/cdirs/cosmo/work/legacysurvey/dr10/images\",\n",
    "                                    patch_size=224,\n",
    "                                    max_distortions=4,\n",
    "                                    num_levels=5,\n",
    "                                    pristine_prob=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74872bf3-ab04-4862-b0c0-e44f905df574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_773996/3810689271.py:96: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cosphi = math.cos(phi)\n",
      "/tmp/ipykernel_773996/3810689271.py:97: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sinphi = math.sin(phi)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DECAMDataset.__getitem__(train_dataset, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0805f2b-f556-44c3-8ee8-65a641762c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
